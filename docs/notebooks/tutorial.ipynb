{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[ShallowLearn](https://github.com/giacbrd/ShallowLearn) is a small collection of algorithms for supervised learning, which expose the same interface of the classification models in Scikit-learn. The idea started with the publication of [fastText](https://fasttext.cc), a library that, among other models, implements a text classification algorithm with an approach reminiscent of the popular *word2vec*. The supervised learnig model is a simple neaural network, very close to the CBOW model of word2vec. Instead of computing only word representations, it also calculates label prepresentations, according to their relations with the words of labled text documents.\n",
    "The original fastText tutorial is available at https://github.com/facebookresearch/fastText/blob/master/tutorials/supervised-learning.md , **here I am going to reproduce the same tutorial and describe some further features of fastText in ShallowLearn**.\n",
    "In ShallowLearn the fastText algorithm is reimplemented in the model `GensimFastText`, which is a Python + Cython implementation, mainly based on the word2vec code of Gensim, that is robust and performant (see https://rare-technologies.com/word2vec-tutorial/). The resulting code is still very efficient, but it also drops some limits of the original fastText, and it is usable in the Scikit-learn framewrok."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Install ShallowLearn following the [README](https://github.com/giacbrd/ShallowLearn/blob/master/README.rst).\n",
    "As in the above mentioned tutorial, for testing we will use data from the cooking section of Stackexchange."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import urllib, tempfile\n",
    "remote_file = urllib.URLopener()\n",
    "temp_file = tempfile.NamedTemporaryFile()\n",
    "remote_file.retrieve('https://s3-us-west-1.amazonaws.com/fasttext-vectors/cooking.stackexchange.tar.gz', temp_file.name)\n",
    "#TODO use islice for dataset splitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Instead of defining a single split of a training and a validation set, we will use Scikit-learn tools for evaluation. Results won't be comparable with the original tutorial, but we will have a more solid evaluation by using, e.g., k-fold cross validation.\n",
    "First, we need to load the data in memory, even if `GensimFastText` can work on iterables, so it could \"stream\" data from disk/network. We transform the data in two lists of samples content and labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "instead of random trials, better to use sklearn.model_selection.GridSearchCV for finding the optimal paramter values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "pre-trained vectors maybe dont improve accuracy, but fastText may converge faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Further readings\n",
    "PR on Gensim https://github.com/RaRe-Technologies/gensim/pull/1153"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
